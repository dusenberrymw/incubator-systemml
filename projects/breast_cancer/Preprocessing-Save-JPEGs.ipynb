{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from breast_cancer import input_data\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# spark = (SparkSession.builder.appName(\"KerasResNet50\").getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "size = 256\n",
    "channels = 3\n",
    "features = size * size * channels\n",
    "classes = 3\n",
    "p = 0.01\n",
    "val_p = 0.01\n",
    "use_caching = False\n",
    "normalize_class_distribution = False\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read in train & val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read and sample from full DataFrames\n",
    "train_df = input_data.read_train_data(spark, size, channels, p, normalize_class_distribution, seed)\n",
    "val_df = input_data.read_val_data(spark, size, channels, val_p, normalize_class_distribution, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Save DataFrames (Optional)\n",
    "# mode = \"error\"\n",
    "# tr_sample_filename = os.path.join(\"data\", \"train_{}_sample_{}.parquet\".format(p, size))\n",
    "# val_sample_filename = os.path.join(\"data\", \"val_{}_sample_{}.parquet\".format(val_p, size))\n",
    "# train_df.write.mode(mode).save(tr_sample_filename, format=\"parquet\")\n",
    "# val_df.write.mode(mode).save(val_sample_filename, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if use_caching:\n",
    "  train_df.cache()\n",
    "  val_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Explore class distributions.\n",
    "for df in [train_df, val_df]:\n",
    "  df.select(\"tumor_score\").groupBy(\"tumor_score\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tc = train_df.count()\n",
    "vc = val_df.count()\n",
    "print(tc, vc)  # 3560187 910918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sanity check that there are no duplicates.\n",
    "assert train_df.dropDuplicates().count() == tc\n",
    "assert val_df.dropDuplicates().count() == vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute image channel means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_means = input_data.compute_channel_means(train_df, channels, size)\n",
    "val_means = input_data.compute_channel_means(val_df, channels, size)\n",
    "print(tr_means.shape)\n",
    "print(tr_means, val_means)\n",
    "# Train: [ 194.27633667  145.3067627   181.27861023]\n",
    "# Val: [ 192.92971802  142.83534241  180.18870544]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save every image as a JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def array_to_img(x, channels, size):\n",
    "  x = x.reshape((channels,size,size)).transpose((1,2,0))  # shape (N,H,W,C)\n",
    "  img = Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def helper(row, channels, size, save_dir):\n",
    "  tumor_score = row.tumor_score\n",
    "  sample = row.sample.values\n",
    "  img = array_to_img(sample, channels, size)\n",
    "  filename = '{index}_{slide_num}_{hash}.jpeg'.format(\n",
    "      index=row[\"__INDEX\"], slide_num=row.slide_num, hash=np.random.randint(1e4))\n",
    "  class_dir = os.path.join(save_dir, str(tumor_score))\n",
    "  path = os.path.join(class_dir, filename)\n",
    "  img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_save_dir = \"images/{stage}/{p}\".format(stage=\"train\", p=p)\n",
    "val_save_dir = \"images/{stage}/{p}\".format(stage=\"val\", p=val_p)\n",
    "print(tr_save_dir, val_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$tr_save_dir\" \"$val_save_dir\"\n",
    "for i in 1 2 3\n",
    "do\n",
    "  sudo mkdir -p $1/$i\n",
    "  sudo mkdir -p $2/$i\n",
    "done\n",
    "sudo chmod 777 -R $1\n",
    "sudo chmod 777 -R $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note: Use this if the DataFrame doesn't have an __INDEX column yet.\n",
    "train_df = train_df.withColumn(\"__INDEX\", F.monotonically_increasing_id())\n",
    "val_df = val_df.withColumn(\"__INDEX\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df.rdd.foreach(lambda row: helper(row, channels, size, tr_save_dir))\n",
    "val_df.rdd.foreach(lambda row: helper(row, channels, size, val_save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_random_image(save_dir):\n",
    "  c = np.random.randint(1, 4)\n",
    "  class_dir = os.path.join(save_dir, str(c))\n",
    "  files = os.listdir(class_dir)\n",
    "  i = np.random.randint(0, len(files))\n",
    "  fname = os.path.join(class_dir, files[i])\n",
    "  print(fname)\n",
    "  img = Image.open(fname)\n",
    "  plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show_random_image(tr_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Spark 2.x + SystemML",
   "language": "python",
   "name": "pyspark3_2.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
